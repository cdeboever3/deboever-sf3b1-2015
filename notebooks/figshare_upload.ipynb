{
 "metadata": {
  "name": "",
  "signature": "sha256:dbbc404a35faa71124a8dd2b84284ac41392c16ba5b73959c6fe2ac2ee8e4a2c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Figshare\n",
      "\n",
      "In this notebook, I'll upload files to figshare. I will\n",
      "upload primary data files like splice junction coverage\n",
      "or gene expression, intermediate data files such as \n",
      "DEXSeq results or branchpoint prediction, and I'll update\n",
      "\"final\" files such as figures and tables.\n",
      "\n",
      "Throughout this notebook I'll refer to paths relative to \n",
      "the main git directory for this project. So if the git \n",
      "repository is located at `/home/user/deboever-sf3b1-2014` \n",
      "and I refer to the directory `data`, I'm referring to\n",
      "`/home/user/deboever-sf3b1-2014/data`.\n",
      "\n",
      "Note that it is unlikely that this file will be useful to \n",
      "anyone except me because I'm the only one uploading data \n",
      "for this project. However, feel free to take a look at what\n",
      "I've done for ideas or use this as boilerplate."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob\n",
      "import hashlib\n",
      "import os\n",
      "import subprocess\n",
      "import urllib2\n",
      "\n",
      "import ds2014 as ds\n",
      "import figshare\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Figshare article ID for the fileset for this project\n",
      "ARTICLE_ID = '1066525'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def md5(path):\n",
      "    \"\"\"Get md5 checksum\"\"\"\n",
      "    cs = subprocess.check_output(['md5',path]).strip().split(' = ')[1]\n",
      "    return cs\n",
      "\n",
      "def get_files(path):\n",
      "    \"\"\"Get full paths for all files whose prefix is path\"\"\"\n",
      "    if os.path.isfile(path):\n",
      "        return [path]\n",
      "    elif os.path.isdir(path):\n",
      "        paths = glob.glob(os.path.join(path,'*'))\n",
      "        out = []\n",
      "        for p in paths:\n",
      "            out += get_files(p)\n",
      "        return out\n",
      "    else:\n",
      "        return None\n",
      "    \n",
      "def hashfile(afile, hasher, blocksize=65536):\n",
      "    \"\"\"\n",
      "    Create SHA hash\n",
      "    \n",
      "    From http://stackoverflow.com/questions/3431825/generating-a-md5-checksum-of-a-file\n",
      "    \"\"\"\n",
      "    buf = afile.read(blocksize)\n",
      "    while len(buf) > 0:\n",
      "        hasher.update(buf)\n",
      "        buf = afile.read(blocksize)\n",
      "    return hasher.hexdigest()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Figshare client\n",
      "\n",
      "I'm using the pypi package `figshare` to interact\n",
      "with figshare. The package was originally designed\n",
      "as a command line interface but [I've branched it](https://github.com/cdeboever3/figshare)\n",
      "and added some functionality as well as exposed parts to \n",
      "be used as a python package.\n",
      "\n",
      "### Setting up\n",
      "\n",
      "You can install the `figshare` package from my repository \n",
      "using the standard `python setup.py install`. Try running\n",
      "`figshare` at the command line and set up your access token\n",
      "file. By default it is stored at `~/.figshare-token`. Once \n",
      "you've done this, you can upload files."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Initialize figshare client\n",
      "token_file = os.path.expanduser('~/.figshare-token')\n",
      "access_token, access_token_secret = figshare.oauth_dance.read_token_file(token_file)\n",
      "fg = figshare.Figshare(figshare.consumer_key, \n",
      "                       figshare.consumer_secret, \n",
      "                       access_token, \n",
      "                       access_token_secret)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Figshare manifest\n",
      "\n",
      "I have a manifest file in the figshare fileset that describes\n",
      "what files are uploaded to figshare and their md5\n",
      "checksums. We'll download that file and check against\n",
      "what we already have available in the local repository. \n",
      "Any missing files or files whose checksums differ from \n",
      "those on figshare will be downloaded.\n",
      "\n",
      "If the manifest doesn't exist, this \n",
      "is the first upload and we'll create it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "details = fg.article_details(ARTICLE_ID)\n",
      "figshare_files = [ x['name'] for x in details['items'][0]['files'] ]\n",
      "download_urls = dict([ [x['name'], x['download_url']] for x in details['items'][0]['files'] ])\n",
      "\n",
      "if 'manifest.txt' in figshare_files:\n",
      "    lines = urllib2.urlopen(download_url['manifest.txt']).read().strip().split('\\n')\n",
      "    figshare_cs = dict([ x.split('\\t') for x in lines ])\n",
      "else:\n",
      "    figshare_cs = None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Upload\n",
      "\n",
      "### Primary data\n",
      "\n",
      "Primary data is located in the `data` directory. These are\n",
      "files that are not created by any of the notebooks in this\n",
      "repository.\n",
      "\n",
      "### Output from notebooks\n",
      "\n",
      "The output files from the notebooks located in `notebooks` \n",
      "are stored in `output`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "local_files = []\n",
      "\n",
      "# Primary data\n",
      "subdir = os.path.join(ds.root, 'data')\n",
      "local_files += get_files(subdir)\n",
      "\n",
      "# Output from notebooks \n",
      "subdir = os.path.join(ds.root, 'output')\n",
      "local_files += get_files(subdir)\n",
      "\n",
      "upload_paths = dict(zip([ os.path.split(x)[1] for x in local_files ],\n",
      "                        local_files))\n",
      "\n",
      "local_cs = dict(zip(upload_paths.keys(),\n",
      "                    [(fname, hashfile(open(fname, 'rb'), hashlib.sha256())) for fname in upload_paths.values()]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "upload_manifest = False\n",
      "if figshare_cs:\n",
      "    for f in local_cs.keys():\n",
      "        if f not in figshare_cs.keys():\n",
      "            fg.upload_file(ARTICLE_ID, upload_paths[f])\n",
      "            upload_manifest = True\n",
      "        elif local_cs[f] != figshare_cs[f]:\n",
      "            fg.upload_file(ARTICLE_ID, upload_paths[f])\n",
      "            upload_manifest = True\n",
      "else:\n",
      "    upload_manifest = True\n",
      "    for f in local_cs.keys():\n",
      "        fg.upload_file(ARTICLE_ID, upload_paths[f])\n",
      "    \n",
      "# If we have to upload the manifest, we'll update the \n",
      "# checksums for all the file we just uploaded\n",
      "if upload_manifest:\n",
      "    for k in local_cs.keys():\n",
      "        figshare_cs[k] = local_cs[k]\n",
      "    pd.Series(figshare_cs).to_csv(ds.manifest)\n",
      "    fg.upload_file(ARTICLE_ID, ds.manifest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}