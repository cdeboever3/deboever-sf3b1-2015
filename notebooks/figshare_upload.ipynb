{
 "metadata": {
  "name": "",
  "signature": "sha256:2f32cb6b7f2f6d71180dc441df18d918003a0f60419f051c37502aba1ba36842"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Figshare\n",
      "\n",
      "In this notebook, I'll upload files to figshare. I will\n",
      "upload primary data files like splice junction coverage\n",
      "or gene expression, intermediate data files such as \n",
      "DEXSeq results or branchpoint prediction, and I'll update\n",
      "\"final\" files such as figures and tables.\n",
      "\n",
      "Throughout this notebook I'll refer to paths relative to \n",
      "the main git directory for this project. So if the git \n",
      "repository is located at `/home/user/deboever-sf3b1-2014` \n",
      "and I refer to the directory `data`, I'm referring to\n",
      "`/home/user/deboever-sf3b1-2014/data`.\n",
      "\n",
      "Note that it is unlikely that this file will be useful to \n",
      "anyone except me because I'm the only one uploading data \n",
      "for this project. However, feel free to take a look at what\n",
      "I've done for ideas or use this as boilerplate."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob\n",
      "import hashlib\n",
      "import os\n",
      "import subprocess\n",
      "import urllib2\n",
      "\n",
      "import ds2014 as ds\n",
      "import figshare\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_files(path):\n",
      "    \"\"\"Get full paths for all files whose prefix is path\"\"\"\n",
      "    if os.path.isfile(path):\n",
      "        return [path]\n",
      "    elif os.path.isdir(path):\n",
      "        paths = glob.glob(os.path.join(path,'*'))\n",
      "        out = []\n",
      "        for p in paths:\n",
      "            out += get_files(p)\n",
      "        return out\n",
      "    else:\n",
      "        return None\n",
      "    \n",
      "def hashfile(fname, hasher=hashlib.sha256(), blocksize=65536):\n",
      "    \"\"\"\n",
      "    Create SHA hash\n",
      "    \n",
      "    From http://stackoverflow.com/questions/3431825/generating-a-md5-checksum-of-a-file\n",
      "    \"\"\"\n",
      "    afile = open(fname, 'rb')\n",
      "    buf = afile.read(blocksize)\n",
      "    while len(buf) > 0:\n",
      "        hasher.update(buf)\n",
      "        buf = afile.read(blocksize)\n",
      "    afile.close()\n",
      "    return hasher.hexdigest()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Figshare client\n",
      "\n",
      "I'm using the pypi package `figshare` to interact\n",
      "with figshare. The package was originally designed\n",
      "as a command line interface but [I've branched it](https://github.com/cdeboever3/figshare)\n",
      "and added some functionality as well as exposed parts to \n",
      "be used as a python package.\n",
      "\n",
      "### Setting up\n",
      "\n",
      "You can install the `figshare` package from my repository \n",
      "using the standard `python setup.py install`. Try running\n",
      "`figshare` at the command line and set up your access token\n",
      "file. By default it is stored at `~/.figshare-token`. Once \n",
      "you've done this, you can upload files."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Initialize figshare client\n",
      "token_file = os.path.expanduser('~/.figshare-token')\n",
      "access_token, access_token_secret = figshare.oauth_dance.read_token_file(token_file)\n",
      "fg = figshare.Figshare(figshare.consumer_key, \n",
      "                       figshare.consumer_secret, \n",
      "                       access_token, \n",
      "                       access_token_secret)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Figshare manifest\n",
      "\n",
      "I have a manifest file in the figshare fileset that describes\n",
      "what files are uploaded to figshare and their sha256\n",
      "hashes. We'll download that file and check against\n",
      "what we already have available in the local repository. \n",
      "Any missing files or files whose hashes differ from \n",
      "those on figshare will be downloaded.\n",
      "\n",
      "If the manifest doesn't exist, this \n",
      "is the first upload and we'll create it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "details = fg.article_details(ds.figshare_article_id)\n",
      "figshare_files = [ x['name'] for x in details['items'][0]['files'] ]\n",
      "download_urls = dict([ [x['name'], x['download_url']] for x in details['items'][0]['files'] ])\n",
      "\n",
      "if 'manifest.txt' in figshare_files:\n",
      "    lines = urllib2.urlopen(download_url['manifest.txt']).read().strip().split('\\n')\n",
      "    figshare_hashes = dict([ x.split('\\t') for x in lines ])\n",
      "else:\n",
      "    figshare_hashes = None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Upload\n",
      "\n",
      "### Primary data\n",
      "\n",
      "Primary data is located in the `data` directory. These are\n",
      "files that are not created by any of the notebooks in this\n",
      "repository.\n",
      "\n",
      "### Output from notebooks\n",
      "\n",
      "The output files from the notebooks located in `notebooks` \n",
      "are stored in `output`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "local_files = []\n",
      "\n",
      "# Primary data\n",
      "subdir = os.path.join(ds.root, 'data')\n",
      "local_files += get_files(subdir)\n",
      "\n",
      "# Output from notebooks \n",
      "subdir = os.path.join(ds.root, 'output')\n",
      "local_files += get_files(subdir)\n",
      "\n",
      "upload_paths = dict(zip([ os.path.split(x)[1] for x in local_files ],\n",
      "                        local_files))\n",
      "\n",
      "local_hashes = dict(zip(upload_paths.keys(),\n",
      "                    [hashfile(fname) for fname in upload_paths.values()]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "upload_manifest = False\n",
      "if figshare_hashes:\n",
      "    for f in local_hashes.keys():\n",
      "        if f not in figshare_hashes.keys():\n",
      "            fg.upload_file(ds.figshare_article_id, upload_paths[f])\n",
      "            upload_manifest = True\n",
      "        elif local_hashes[f] != figshare_hashes[f]:\n",
      "            fg.upload_file(ds.figshare_article_id, upload_paths[f])\n",
      "            upload_manifest = True\n",
      "else:\n",
      "    upload_manifest = True\n",
      "    for f in local_hashes.keys():\n",
      "        fg.upload_file(ds.figshare_article_id, upload_paths[f])\n",
      "    \n",
      "# If we have to upload the manifest, we'll update the \n",
      "# hashes for all the files we just uploaded\n",
      "if upload_manifest:\n",
      "    for k in local_hashes.keys():\n",
      "        figshare_hashes[k] = local_hashes[k]\n",
      "    pd.Series(figshare_hashes).to_csv(ds.manifest)\n",
      "    fg.upload_file(ds.figshare_article_id, ds.manifest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "No JSON object could be decoded",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-8-3636828fc053>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mupload_manifest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlocal_hashes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mARTICLE_ID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupload_paths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# If we have to upload the manifest, we'll update the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/raid/development/cdeboever/software/anaconda1.9.1/envs/sf3b1-vc/lib/python2.7/site-packages/figshare/figshare.pyc\u001b[0m in \u001b[0;36mupload_file\u001b[1;34m(self, article_id, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     48\u001b[0m             response = self.client.put('%s/articles/%s/files' % (self.endpoint, article_id),\n\u001b[0;32m     49\u001b[0m                                        files=files)\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mown_handle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/raid/development/cdeboever/software/anaconda1.9.1/envs/sf3b1-vc/lib/python2.7/json/__init__.pyc\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    336\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/raid/development/cdeboever/software/anaconda1.9.1/envs/sf3b1-vc/lib/python2.7/json/decoder.pyc\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \"\"\"\n\u001b[1;32m--> 366\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/raid/development/cdeboever/software/anaconda1.9.1/envs/sf3b1-vc/lib/python2.7/json/decoder.pyc\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    382\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No JSON object could be decoded\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: No JSON object could be decoded"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}