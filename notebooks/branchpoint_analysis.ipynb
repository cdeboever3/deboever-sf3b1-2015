{
 "metadata": {
  "name": "",
  "signature": "sha256:9f86ad88ee15811df7b759f148c8d140492ff4008a5c58065e27f2691fdea031"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Branchpoint Analysis\n",
      "\n",
      "In this notebook, I'm going to use SVM_BP to predict branchpoints. \n",
      "I'll predict branchpoints for junctions with cryptic acceptors whose usage differs \n",
      "significantly between the *SF3B1* mutant and wild-type samples. I'll split\n",
      "these into junction with cryptic acceptors 10-30 bp upstream of an annotated \n",
      "acceptor and junctions not 10-30 bp upstream of an annotated acceptor. For the\n",
      "cryptic junctions with an acceptor 10-30 bp upstream of an annotated acceptor,\n",
      "I'll also predict the branchpoint for the annotated acceptor. I will also \n",
      "choose some \"control\" junctions that are highly expressed but don't have\n",
      "proximal cryptic junctions and predict branchpoints for those."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob\n",
      "import os\n",
      "import shutil\n",
      "import subprocess\n",
      "from urllib2 import urlopen\n",
      "\n",
      "from Bio.Seq import Seq\n",
      "import ds2014 as ds\n",
      "import pandas as pd\n",
      "import pybedtools as pbt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "curdir = os.getcwd()\n",
      "outdir = os.path.join(os.path.split(curdir)[0], \n",
      "                      'output', \n",
      "                      'branchpoint_analysis')\n",
      "ds.makedir(outdir)\n",
      "\n",
      "results = pd.read_table(ds.brca_cll_um_dexseq_results,\n",
      "                        index_col=0,\n",
      "                        header=0)\n",
      "\n",
      "counts = pd.read_table(ds.brca_cll_um_sj_counts,\n",
      "                       index_col=0,\n",
      "                       header=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Define junctions\n",
      "\n",
      "Let's define the different classes of junctions we are looking at:\n",
      "* proximal cryptic junction with novel acceptor 10-30 bp upstream \n",
      "of annotated acceptor\n",
      "* distal cryptic junction with novel acceptor **not** 10-30 bp \n",
      "upstream of annotated acceptor\n",
      "* annotated junction with proximal cryptic acceptor 10-30 bp upstream\n",
      "* control junction\n",
      "\n",
      "### Proximal cryptic junctions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = ds.proximal_jxns\n",
      "if not os.path.exists(f):\n",
      "    proximal_jxns = results[(results.padjust < ds.dexseq_p_cutoff) &\n",
      "                            (results.downstream_acceptor_dist <= 30) &\n",
      "                            (results.downstream_acceptor_dist >= 10) &\n",
      "                            (results['log2fold(MUT/WT)'] > 0)]\n",
      "    proximal_jxns = pd.Series(proximal_jxns.index)\n",
      "    proximal_jxns.to_csv(f, sep='\\t', index=False, header=False)\n",
      "else:\n",
      "    proximal_jxns = pd.read_table(f, header=None, squeeze=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Distal cryptic junctions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = ds.distal_jxns\n",
      "if not os.path.exists(f):\n",
      "    distal_jxns = results[(results.padjust < ds.dexseq_p_cutoff) &\n",
      "                          (results.downstream_acceptor_dist > 30) &\n",
      "                          (results['log2fold(MUT/WT)'] > 0)]\n",
      "    distal_jxns = pd.Series(distal_jxns.index)\n",
      "    distal_jxns.to_csv(f, sep='\\t', index=False, header=False)\n",
      "else:\n",
      "    distal_jxns = pd.read_table(f, header=None, squeeze=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Annotated junctions downstream of proximal cryptic junctions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_annotated_jxn(row):\n",
      "    \"\"\"\n",
      "    Define the downstream annotated junction for a \n",
      "    junction with a novel acceptor using a row\n",
      "    from the results table\n",
      "    \"\"\"\n",
      "    if row['strand'] == '+':        \n",
      "        return '{}:{}-{}:{}'.format(row['chrom'], \n",
      "                                    row['start'],\n",
      "                                    row['end'] + int(row['downstream_acceptor_dist']),\n",
      "                                    row['strand'])\n",
      "    if row['strand'] == '-':\n",
      "        return '{}:{}-{}:{}'.format(row['chrom'], \n",
      "                                    row['start'] - int(row['downstream_acceptor_dist']),\n",
      "                                    row['end'],\n",
      "                                    row['strand'])\n",
      "\n",
      "f = ds.annot_jxns\n",
      "if not os.path.exists(f):\n",
      "    annot_jxns = pd.Series(results.ix[proximal_jxns].apply(lambda x: get_annotated_jxn(x), axis=1))\n",
      "    annot_jxns.index = arange(annot_jxns.shape[0])\n",
      "    annot_jxns.to_csv(f, sep='\\t', index=False, header=False)\n",
      "else:\n",
      "    annot_jxns = pd.read_table(f, header=None, squeeze=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I'll also make a mapping between the proximal cryptic \n",
      "junctions and the annotated junctions 10-30 bp downsteam."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = ds.proximal_to_annot\n",
      "if not os.path.exists(f):\n",
      "    proximal_to_annot = pd.Series(annot_jxns.values,\n",
      "                                  index=proximal_jxns,\n",
      "                                  name='annotated')\n",
      "    proximal_to_annot.index.name = 'proximal_cryptic'\n",
      "    proximal_to_annot.to_csv(f, sep='\\t')\n",
      "else:\n",
      "    proximal_to_annot = pd.read_table(f, index_col=0, header=0,\n",
      "                                      squeeze=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Control junctions\n",
      "\n",
      "For control junctions, we will choose junctions that\n",
      "are annotated in Gencode, whose average coverage over \n",
      "all samples is greater than 100, and whose donor does \n",
      "not have any novel acceptors."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = ds.control_jxns\n",
      "if not os.path.exists(f):\n",
      "    donors = set(results[results.ext_annotated == False]['donor'])\n",
      "    control_jxns = results[(results.ext_annotated) &\n",
      "                           (results.donor.apply(lambda x: x not in donors)) & \n",
      "                           (counts.ix[results.index].mean(axis=1) > 100)]\n",
      "    control_jxns = pd.Series(control_jxns.index)\n",
      "    control_jxns.to_csv(f, sep='\\t', index=False, header=False)\n",
      "else:\n",
      "    control_jxns = pd.read_table(f, header=None, squeeze=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Sequence files\n",
      "\n",
      "To predict branchpoints, we need the last 50 bp of the intron for\n",
      "each junction. I'll reverse complemen minus strand sequence."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_seq(row):\n",
      "    \"\"\"Get last 50 bp of intron for a row from results table\"\"\"\n",
      "    if row['strand'] == '+':\n",
      "        seq_pos = '{0}:{1}-{2}'.format(row['chrom'],\n",
      "                                       int(row['end'] - 49),\n",
      "                                       int(row['end']))\n",
      "        seq = pbt.BedTool.seq(seq_pos, ds.hg19)\n",
      "    elif row['strand'] == '-':\n",
      "        seq_pos = '{0}:{1}-{2}'.format(row['chrom'],\n",
      "                                       int(row['start']),\n",
      "                                       int(row['start'] + 49))\n",
      "        seq = pbt.BedTool.seq(seq_pos, ds.hg19)\n",
      "        my_seq = Seq(seq)\n",
      "        seq = my_seq.reverse_complement().tostring()\n",
      "    return seq\n",
      "\n",
      "def make_intron_fasta(res, f):\n",
      "    \"\"\"Make fasta file of last 50 bp of intron for results table\"\"\"\n",
      "    r = res.apply(lambda x: get_seq(x), axis=1)\n",
      "    with open(f, 'w') as fout:\n",
      "        for i in r.index:\n",
      "            fout.write('>{}\\n'.format(i))\n",
      "            fout.write(r[i] + '\\n')\n",
      "\n",
      "f = ds.proximal_intron_seq\n",
      "if not os.path.exists(f):\n",
      "    make_intron_fasta(results.ix[proximal_jxns], f)\n",
      "\n",
      "f = ds.distal_intron_seq\n",
      "if not os.path.exists(f):\n",
      "    make_intron_fasta(results.ix[distal_jxns], f)\n",
      "    \n",
      "f = ds.annot_intron_seq\n",
      "if not os.path.exists(f):\n",
      "    # We have to account for the possibility that the \n",
      "    # annotated junction didn't make it through the sjout filtering.\n",
      "    make_intron_fasta(results.ix[annot_jxns].dropna(subset=['chrom']).drop_duplicates(), f)\n",
      "    \n",
      "f = ds.control_intron_seq\n",
      "if not os.path.exists(f):\n",
      "    make_intron_fasta(results.ix[control_jxns], f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Predict branchpoints\n",
      "\n",
      "I'm going to use SVM_BP to predict branchpoint locations.\n",
      "I have forked [my own version](https://github.com/cdeboever3/svm-bpfinder) of SVM_BP where I have changed\n",
      "a hard-coded parameter that specifies the minimum distance \n",
      "from the 3' splice-site to the branchpoint. This was originally\n",
      "15 bp but I changed to 8 bp because if proximal cryptic junctions\n",
      "use the same branchpoint as their downstream annotated acceptors,\n",
      "they may be closer than 15 bp to the branchpoint."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict_branchpoints(intron_fasta):\n",
      "    lines = subprocess.check_output([os.path.join(ds.root, 'software', 'svm-bpfinder', 'svm_bpfinder.py'),\n",
      "                                     intron_fasta, 'Hsap', '50'])\n",
      "    lines = [ x.split('\\t') for x in lines.strip().split('\\n') ]\n",
      "    return pd.DataFrame(lines[1:], columns=lines[0])\n",
      "\n",
      "f = ds.proximal_all_bp\n",
      "if not os.path.exists(f):\n",
      "    proximal_all_bp = predict_branchpoints(ds.proximal_intron_seq)\n",
      "    proximal_all_bp.to_csv(f, index=None, sep='\\t')\n",
      "else:\n",
      "    proximal_all_bp = pd.read_table(f, index_col=None, header=0)\n",
      "    \n",
      "f = ds.distal_all_bp\n",
      "if not os.path.exists(f):\n",
      "    distal_all_bp = predict_branchpoints(ds.distal_intron_seq)\n",
      "    distal_all_bp.to_csv(f, index=None, sep='\\t')\n",
      "else:\n",
      "    distal_all_bp = pd.read_table(f, index_col=None, header=0)\n",
      "    \n",
      "f = ds.annot_all_bp\n",
      "if not os.path.exists(f):\n",
      "    annot_all_bp = predict_branchpoints(ds.annot_intron_seq)\n",
      "    annot_all_bp.to_csv(f, index=None, sep='\\t')\n",
      "else:\n",
      "    annot_all_bp = pd.read_table(f, index_col=None, header=0)\n",
      "    \n",
      "f = ds.control_all_bp\n",
      "if not os.path.exists(f):\n",
      "    control_all_bp = predict_branchpoints(ds.control_intron_seq)\n",
      "    control_all_bp.to_csv(f, sep='\\t', index=None)\n",
      "else:\n",
      "    control_all_bp = pd.read_table(f, index_col=None, header=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### SVM_BP output\n",
      "\n",
      "The SVM_BP output has the following columns:\n",
      "\n",
      "* seq_id - Sequence Identifier\n",
      "* agez - AG dinucleotide Exclusion Zone length\n",
      "* ss_dist - Distance to 3' splice site\n",
      "* bp_seq - BP sequence (nonamer; from -5 to +3 relative to the BP adenine)\n",
      "* bp_scr - BP sequence score using a variable order Markov model\n",
      "* y_cont - Pyrimidine content between the BP adenine and the 3' splice site\n",
      "* ppt_off - Polypyrimidine tract offset relative to the BP adenine\n",
      "* ppt_len - Polypyrimidine tract length\n",
      "* ppt_scr - Polypyrimidine tract score\n",
      "* svm_scr - Final BP score using the SVM classifier\n",
      "\n",
      "### Single branchpoint per junction/intron\n",
      "\n",
      "SVM_BP can predict more than one branchpoint per \n",
      "intron (or none at all). I want to choose a \"best\"\n",
      "prediction for each intron for the branchpoint. This \n",
      "will make some downstream analyses easier. \n",
      "\n",
      "#### Annotated acceptors downstream of proximal cryptic junctions\n",
      "\n",
      "To simplify downstream analyses, I'm only going to keep \n",
      "predictions for pairs of proximal junctions and their \n",
      "downstream annotated junction when branchpoints are \n",
      "predicted for both. \n",
      "\n",
      "Note that while we can always figure out the annotated junction\n",
      "for a proximal cryptic junction, we may not always have coverage\n",
      "data for that annotated junction. This happens when the annotated\n",
      "junction's coverage is not above the cutoff we used when combining\n",
      "`SJ.out.tab` files. In practice this is rare and I think only observed\n",
      "for one cryptic junction/annotated junction pair here. We will exclude\n",
      "these junctions.\n",
      "\n",
      "Another a rare thing that can happen is that an annotated junction\n",
      "can have two cryptic junctions upstream. I think there are five annotated\n",
      "junctions here that have two cryptic junctions upstream. We will choose\n",
      "one of these cryptic acceptors and discard the other.\n",
      "\n",
      "#### Additional information\n",
      "\n",
      "I'd like to add some extra information to the dataframes\n",
      "that have the branchpoint results. \n",
      "\n",
      "* Annotated junction for proximal cryptic acceptors and vice versa.\n",
      "* Distance from cryptic acceptor to annotated acceptor for\n",
      "proximal cryptic junctions and their associated annotated \n",
      "junctions.\n",
      "* Whether associated proximal and annotated junctions share\n",
      "predicted branchpoints.\n",
      "* Distance from branchpoint predict for annotated junction to\n",
      "cryptic associated proximal cryptic junction."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    proximal_single_bp = make_uniq_bp_results(proximal_all_bp)\n",
      "    annot_single_bp = make_uniq_bp_results(annot_all_bp)\n",
      "    # Add annotated jxn for proximal cryptic\n",
      "    proximal_single_bp['annotated'] = [ proximal_to_annot[x] for x in proximal_single_bp.index ]\n",
      "    # Keep one proximal junction per annotated junction\n",
      "    proximal_single_bp = proximal_single_bp.drop_duplicates(subset=['annotated'])\n",
      "    # Keep annotated/proximal junctions only if annotated\n",
      "    # junction has count data\n",
      "    s = set(proximal_single_bp.annotated) - set(counts.index)\n",
      "    proximal_single_bp = proximal_single_bp[proximal_single_bp.annotated.apply(lambda x: x not in s)]\n",
      "    # Keep proximal only if annotated had a branchpoint predicted\n",
      "    proximal_single_bp = proximal_single_bp[proximal_single_bp.annotated.apply(lambda x: x in annot_single_bp.index)]\n",
      "    # Updated results for annotated junctions\n",
      "    annot_single_bp = annot_single_bp.ix[proximal_single_bp.annotated]\n",
      "    # Add proximal crytpic jxn for downstream annotated jxns\n",
      "    annot_to_proximal = pd.Series(dict(zip(proximal_single_bp.annotated, \n",
      "                                           proximal_single_bp.index)))\n",
      "    annot_single_bp['cryptic'] = annot_to_proximal.ix[annot_single_bp.index].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Add distance between annotated and proximal cryptic jxns\n",
      "proximal_single_bp['downstream_acceptor_dist'] = results.ix[proximal_single_bp.index,\n",
      "                                                            'downstream_acceptor_dist']\n",
      "annot_single_bp['proximal_cryptic_dist'] = results.ix[annot_single_bp.cryptic, \n",
      "                                                      'downstream_acceptor_dist']\n",
      "# Distance between annotated acceptor's branchpoint and \n",
      "# proximal cryptic acceptor.\n",
      "annot_single_bp['bp_novel_dist'] = annot_single_bp.ss_dist - annot_single_bp.proximal_cryptic_dist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Add column indicating whether the branchpoints\n",
      "# were predicted to be the same for the proximal \n",
      "# cryptic junctions and their associated annotated \n",
      "# junctions.\n",
      "# TODO: I should be able to compare distance here to \n",
      "# do this rather than comparing the sequences as I did before\n",
      "annot_single_bp['match'] = False\n",
      "annot_single_bp.ix[annot_single_bp.bp_seq == proximal_single_bp.ix[annot_single_bp.index,'bp_seq'],'bp_match'] = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_uniq_bp_results(all_bp):\n",
      "    df = all_bp.sort(['seq_id', 'bp_scr'], ascending=False).drop_duplicates('seq_id')\n",
      "    df.index = list(df.seq_id)\n",
      "    return df\n",
      "    \n",
      "f = ds.proximal_single_bp\n",
      "g = ds.annot_single_bp\n",
      "if (not os.path.exists(f)) or (not os.path.exists(g)):\n",
      "    proximal_single_bp = make_uniq_bp_results(proximal_all_bp)\n",
      "    annot_single_bp = make_uniq_bp_results(annot_all_bp)\n",
      "    # Add annotated jxn for proximal cryptic\n",
      "    proximal_single_bp['annotated'] = [ proximal_to_annot[x] for x in proximal_single_bp.index ]\n",
      "    # Keep one proximal junction per annotated junction\n",
      "    proximal_single_bp = proximal_single_bp.drop_duplicates(subset=['annotated'])\n",
      "    # Keep annotated/proximal junctions only if annotated\n",
      "    # junction has count data\n",
      "    s = set(proximal_single_bp.annotated) - set(counts.index)\n",
      "    proximal_single_bp = proximal_single_bp[proximal_single_bp.annotated.apply(lambda x: x not in s)]\n",
      "    # Keep proximal only if annotated had a branchpoint predicted\n",
      "    proximal_single_bp = proximal_single_bp[proximal_single_bp.annotated.apply(lambda x: x in annot_single_bp.index)]\n",
      "    # Updated results for annotated junctions\n",
      "    annot_single_bp = annot_single_bp.ix[proximal_single_bp.annotated]\n",
      "    # Add proximal crytpic jxn for downstream annotated jxns\n",
      "    annot_to_proximal = pd.Series(dict(zip(proximal_single_bp.annotated, \n",
      "                                           proximal_single_bp.index)))\n",
      "    annot_single_bp['cryptic'] = annot_to_proximal.ix[annot_single_bp.index].values\n",
      "\n",
      "    # add distance between annotated and novel splice-sites to annotated dataframe\n",
      "    distL = []\n",
      "    for donor in annot_bp_uniqDF.donor:\n",
      "        distL += list(novel_bp_uniqDF[novel_bp_uniqDF.donor == donor]['annot_novel_dist'].values)\n",
      "    annot_bp_uniqDF['annot_novel_dist'] = distL\n",
      "    # distance between annotated acceptor's BP and novel acceptor\n",
      "    annot_single_bp['bp_novel_dist'] = annot_bp_uniqDF.ss_dist - annot_bp_uniqDF.annot_novel_dist\n",
      "    \n",
      "    proximal_single_bp.to_csv(f, sep='\\t')\n",
      "    annot_single_bp.to_csv(f, sep='\\t')\n",
      "else:\n",
      "    proximal_single_bp = pd.read_table(f, index_col=0,\n",
      "                                       header=0)\n",
      "    annot_single_bp = pd.read_table(f, index_col=0,\n",
      "                                    header=0)\n",
      "\n",
      "f = ds.distal_single_bp\n",
      "if not os.path.exists(f):\n",
      "    distal_single_bp = make_uniq_bp_results(distal_all_bp)\n",
      "    distal_single_bp.to_csv(f, sep='\\t')\n",
      "else:\n",
      "    distal_single_bp = pd.read_table(f, index_col=0,\n",
      "                                     header=0)\n",
      "    \n",
      "f = ds.control_single_bp\n",
      "if not os.path.exists(f):\n",
      "    control_single_bp = make_uniq_bp_results(control_all_bp)\n",
      "    control_single_bp.to_csv(f, sep='\\t')\n",
      "else:\n",
      "    control_single_bp = pd.read_table(f, index_col=0,\n",
      "                                      header=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "'annotated'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-11-41412e0d551a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# junction (an annotated junction can rarely have two upstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# acceptors cryptic).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproximal_to_annot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproximal_single_bp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannot_single_bp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'annotated'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mtdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mproximal_single_bp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproximal_single_bp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/cdeboever/software/anaconda/envs/sf3b1-vc/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   3631\u001b[0m         \u001b[0;31m# For SparseDataFrame's benefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3632\u001b[0m         return self._join_compat(other, on=on, how=how, lsuffix=lsuffix,\n\u001b[0;32m-> 3633\u001b[0;31m                                  rsuffix=rsuffix, sort=sort)\n\u001b[0m\u001b[1;32m   3634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3635\u001b[0m     def _join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
        "\u001b[0;32m/Users/cdeboever/software/anaconda/envs/sf3b1-vc/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   3645\u001b[0m             return merge(self, other, left_on=on, how=how,\n\u001b[1;32m   3646\u001b[0m                          \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3647\u001b[0;31m                          suffixes=(lsuffix, rsuffix), sort=sort)\n\u001b[0m\u001b[1;32m   3648\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3649\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/cdeboever/software/anaconda/envs/sf3b1-vc/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy)\u001b[0m\n\u001b[1;32m     36\u001b[0m                          \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                          copy=copy)\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/cdeboever/software/anaconda/envs/sf3b1-vc/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy)\u001b[0m\n\u001b[1;32m    180\u001b[0m         (self.left_join_keys,\n\u001b[1;32m    181\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m          self.join_names) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/cdeboever/software/anaconda/envs/sf3b1-vc/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m                     \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                     \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m                     \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/cdeboever/software/anaconda/envs/sf3b1-vc/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1682\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1684\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/cdeboever/software/anaconda/envs/sf3b1-vc/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1691\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionaility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/cdeboever/software/anaconda/envs/sf3b1-vc/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/cdeboever/software/anaconda/envs/sf3b1-vc/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2536\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2537\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2538\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2539\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/cdeboever/software/anaconda/envs/sf3b1-vc/lib/python2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0mloc\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0munique\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly\u001b[0m \u001b[0mslice\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \"\"\"\n\u001b[0;32m-> 1156\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/cdeboever/software/anaconda/envs/sf3b1-vc/lib/python2.7/site-packages/pandas/index.so\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3650)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;32m/Users/cdeboever/software/anaconda/envs/sf3b1-vc/lib/python2.7/site-packages/pandas/index.so\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3528)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;32m/Users/cdeboever/software/anaconda/envs/sf3b1-vc/lib/python2.7/site-packages/pandas/hashtable.so\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:11908)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;32m/Users/cdeboever/software/anaconda/envs/sf3b1-vc/lib/python2.7/site-packages/pandas/hashtable.so\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:11861)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;31mKeyError\u001b[0m: 'annotated'"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Second highest-scoring branchpoints\n",
      "\n",
      "Because `SVM_BP` can return multiple branchpoints\n",
      "for a given intron, I'd like to replace the branchpoint\n",
      "prediction for annotated junctions with upstream\n",
      "proximal cryptic junctions with the the second-highest\n",
      "scoring branchpoint *if* the distance between the \n",
      "highest scoring branchpoint and the cryptic junction is \n",
      "not between 13 and 17 base pairs. My hypothesis is that\n",
      "`SVM_BP` has a hard time identify the correct branchpoint \n",
      "for these annotated junctions because they are further\n",
      "from the 3' splice-site than is typical. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}