{
 "metadata": {
  "name": "",
  "signature": "sha256:5de9b0cc670b3be67246e745e01bf26f8aaae4aa0abc786ecffe9d7ddfdcbd24"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Branchpoint Analysis\n",
      "\n",
      "In this notebook, I'm going to use SVM_BP to predict branchpoints. \n",
      "I'll predict branchpoints for junctions with cryptic acceptors whose usage differs \n",
      "significantly between the *SF3B1* mutant and wild-type samples. I'll split\n",
      "these into junction with cryptic acceptors 10-30 bp upstream of an annotated \n",
      "acceptor and junctions not 10-30 bp upstream of an annotated acceptor. For the\n",
      "cryptic junctions with an acceptor 10-30 bp upstream of an annotated acceptor,\n",
      "I'll also predict the branchpoint for the annotated acceptor. I will also \n",
      "choose some \"control\" junctions that are highly expressed but don't have\n",
      "proximal cryptic junctions and predict branchpoints for those."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob\n",
      "import os\n",
      "import shutil\n",
      "import subprocess\n",
      "from urllib2 import urlopen\n",
      "\n",
      "from Bio.Seq import Seq\n",
      "import ds2014 as ds\n",
      "import pandas as pd\n",
      "import pybedtools as pbt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "curdir = os.getcwd()\n",
      "outdir = os.path.join(os.path.split(curdir)[0], \n",
      "                      'output', \n",
      "                      'branchpoint_analysis')\n",
      "ds.makedir(outdir)\n",
      "\n",
      "results = pd.read_table(ds.brca_cll_um_dexseq_results,\n",
      "                        index_col=0,\n",
      "                        header=0)\n",
      "\n",
      "counts = pd.read_table(ds.brca_cll_um_sj_counts,\n",
      "                       index_col=0,\n",
      "                       header=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Define junctions\n",
      "\n",
      "Let's define the different classes of junctions we are looking at:\n",
      "* proximal cryptic junction with novel acceptor 10-30 bp upstream \n",
      "of annotated acceptor\n",
      "* distal cryptic junction with novel acceptor **not** 10-30 bp \n",
      "upstream of annotated acceptor\n",
      "* annotated junction with proximal cryptic acceptor 10-30 bp upstream\n",
      "* control junction\n",
      "\n",
      "### Proximal cryptic junctions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = ds.proximal_jxns\n",
      "if not os.path.exists(f):\n",
      "    proximal_jxns = results[(results.padjust < ds.dexseq_p_cutoff) &\n",
      "                            (results.downstream_acceptor_dist <= 30) &\n",
      "                            (results.downstream_acceptor_dist >= 10) &\n",
      "                            (results['log2fold(MUT/WT)'] > 0)]\n",
      "    proximal_jxns = pd.Series(proximal_jxns.index)\n",
      "    proximal_jxns.to_csv(f, sep='\\t', index=False, header=False)\n",
      "else:\n",
      "    proximal_jxns = pd.read_table(f, header=None, squeeze=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Distal cryptic junctions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = ds.distal_jxns\n",
      "if not os.path.exists(f):\n",
      "    distal_jxns = results[(results.padjust < ds.dexseq_p_cutoff) &\n",
      "                          (results.downstream_acceptor_dist > 30) &\n",
      "                          (results['log2fold(MUT/WT)'] > 0)]\n",
      "    distal_jxns = pd.Series(distal_jxns.index)\n",
      "    distal_jxns.to_csv(f, sep='\\t', index=False, header=False)\n",
      "else:\n",
      "    distal_jxns = pd.read_table(f, header=None, squeeze=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Annotated junctions downstream of proximal cryptic junctions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_annotated_jxn(row):\n",
      "    \"\"\"\n",
      "    Define the downstream annotated junction for a \n",
      "    junction with a novel acceptor using a row\n",
      "    from the results table\n",
      "    \"\"\"\n",
      "    if row['strand'] == '+':        \n",
      "        return '{}:{}-{}:{}'.format(row['chrom'], \n",
      "                                    row['start'],\n",
      "                                    row['end'] + int(row['downstream_acceptor_dist']),\n",
      "                                    row['strand'])\n",
      "    if row['strand'] == '-':\n",
      "        return '{}:{}-{}:{}'.format(row['chrom'], \n",
      "                                    row['start'] - int(row['downstream_acceptor_dist']),\n",
      "                                    row['end'],\n",
      "                                    row['strand'])\n",
      "\n",
      "f = ds.annot_jxns\n",
      "if not os.path.exists(f):\n",
      "    annot_jxns = pd.Series(results.ix[proximal_jxns].apply(lambda x: get_annotated_jxn(x), axis=1))\n",
      "    annot_jxns.index = arange(annot_jxns.shape[0])\n",
      "    annot_jxns.to_csv(f, sep='\\t', index=False, header=False)\n",
      "else:\n",
      "    annot_jxns = pd.read_table(f, header=None, squeeze=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I'll also make a mapping between the proximal cryptic \n",
      "junctions and the annotated junctions 10-30 bp downsteam."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = ds.proximal_to_annot\n",
      "if True:\n",
      "    proximal_to_annot = pd.Series(annot_jxns.values,\n",
      "                                  index=proximal_jxns,\n",
      "                                  name='annotated')\n",
      "    proximal_to_annot.index.name = 'proximal_cryptic'\n",
      "    proximal_to_annot.to_csv(f, sep='\\t')\n",
      "else:\n",
      "    proximal_to_annot = pd.read_table(f, index_col=0, header=0,\n",
      "                                      squeeze=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Control junctions\n",
      "\n",
      "For control junctions, we will choose junctions that\n",
      "are annotated in Gencode, whose average coverage over \n",
      "all samples is greater than 100, and whose donor does \n",
      "not have any novel acceptors."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = ds.control_jxns\n",
      "if not os.path.exists(f):\n",
      "    donors = set(results[results.ext_annotated == False]['donor'])\n",
      "    control_jxns = results[(results.ext_annotated) &\n",
      "                           (results.donor.apply(lambda x: x not in donors)) & \n",
      "                           (counts.ix[results.index].mean(axis=1) > 100)]\n",
      "    control_jxns = pd.Series(control_jxns.index)\n",
      "    control_jxns.to_csv(f, sep='\\t', index=False, header=False)\n",
      "else:\n",
      "    control_jxns = pd.read_table(f, header=None, squeeze=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Sequence files\n",
      "\n",
      "To predict branchpoints, we need the last 50 bp of the intron for\n",
      "each junction. I'll reverse complemen minus strand sequence."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_seq(row):\n",
      "    \"\"\"Get last 50 bp of intron for a row from results table\"\"\"\n",
      "    if row['strand'] == '+':\n",
      "        seq_pos = '{0}:{1}-{2}'.format(row['chrom'],\n",
      "                                       int(row['end'] - 49),\n",
      "                                       int(row['end']))\n",
      "        seq = pbt.BedTool.seq(seq_pos, ds.hg19)\n",
      "    elif row['strand'] == '-':\n",
      "        seq_pos = '{0}:{1}-{2}'.format(row['chrom'],\n",
      "                                       int(row['start']),\n",
      "                                       int(row['start'] + 49))\n",
      "        seq = pbt.BedTool.seq(seq_pos, ds.hg19)\n",
      "        my_seq = Seq(seq)\n",
      "        seq = my_seq.reverse_complement().tostring()\n",
      "    return seq\n",
      "\n",
      "def make_intron_fasta(res, f):\n",
      "    \"\"\"Make fasta file of last 50 bp of intron for results table\"\"\"\n",
      "    r = res.apply(lambda x: get_seq(x), axis=1)\n",
      "    with open(f, 'w') as fout:\n",
      "        for i in r.index:\n",
      "            fout.write('>{}\\n'.format(i))\n",
      "            fout.write(r[i] + '\\n')\n",
      "\n",
      "f = ds.proximal_intron_seq\n",
      "if not os.path.exists(f):\n",
      "    make_intron_fasta(results.ix[proximal_jxns], f)\n",
      "\n",
      "f = ds.distal_intron_seq\n",
      "if not os.path.exists(f):\n",
      "    make_intron_fasta(results.ix[distal_jxns], f)\n",
      "    \n",
      "f = ds.annot_intron_seq\n",
      "if not os.path.exists(f):\n",
      "    # We have to account for the possibility that the \n",
      "    # annotated junction didn't make it through the sjout filtering.\n",
      "    make_intron_fasta(results.ix[annot_jxns].dropna(subset=['chrom']).drop_duplicates(), f)\n",
      "    \n",
      "f = ds.control_intron_seq\n",
      "if not os.path.exists(f):\n",
      "    make_intron_fasta(results.ix[control_jxns], f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Predict branchpoints\n",
      "\n",
      "I'm going to use SVM_BP to predict branchpoint locations.\n",
      "I have forked [my own version](https://github.com/cdeboever3/svm-bpfinder) of SVM_BP where I have changed\n",
      "a hard-coded parameter that specifies the minimum distance \n",
      "from the 3' splice-site to the branchpoint. This was originally\n",
      "15 bp but I changed to 8 bp because if proximal cryptic junctions\n",
      "use the same branchpoint as their downstream annotated acceptors,\n",
      "they may be closer than 15 bp to the branchpoint."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict_branchpoints(intron_fasta):\n",
      "    lines = subprocess.check_output([os.path.join(ds.root, 'software', 'svm-bpfinder', 'svm_bpfinder.py'),\n",
      "                                     intron_fasta, 'Hsap', '50'])\n",
      "    lines = [ x.split('\\t') for x in lines.strip().split('\\n') ]\n",
      "    return pd.DataFrame(lines[1:], columns=lines[0])\n",
      "\n",
      "f = ds.proximal_all_bp\n",
      "if not os.path.exists(f):\n",
      "    proximal_all_bp = predict_branchpoints(ds.proximal_intron_seq)\n",
      "    proximal_all_bp.to_csv(f, index=None, sep='\\t')\n",
      "else:\n",
      "    proximal_all_bp = pd.read_table(f, index_col=None, header=0)\n",
      "    \n",
      "f = ds.distal_all_bp\n",
      "if not os.path.exists(f):\n",
      "    distal_all_bp = predict_branchpoints(ds.distal_intron_seq)\n",
      "    distal_all_bp.to_csv(f, index=None, sep='\\t')\n",
      "else:\n",
      "    distal_all_bp = pd.read_table(f, index_col=None, header=0)\n",
      "    \n",
      "f = ds.annot_all_bp\n",
      "if not os.path.exists(f):\n",
      "    annot_all_bp = predict_branchpoints(ds.annot_intron_seq)\n",
      "    annot_all_bp.to_csv(f, index=None, sep='\\t')\n",
      "else:\n",
      "    annot_all_bp = pd.read_table(f, index_col=None, header=0)\n",
      "    \n",
      "f = ds.control_all_bp\n",
      "if not os.path.exists(f):\n",
      "    control_all_bp = predict_branchpoints(ds.control_intron_seq)\n",
      "    control_all_bp.to_csv(f, sep='\\t', index=None)\n",
      "else:\n",
      "    control_all_bp = pd.read_table(f, index_col=None, header=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### SVM_BP output\n",
      "\n",
      "The SVM_BP output has the following columns:\n",
      "\n",
      "* seq_id - Sequence Identifier\n",
      "* agez - AG dinucleotide Exclusion Zone length\n",
      "* ss_dist - Distance to 3' splice site\n",
      "* bp_seq - BP sequence (nonamer; from -5 to +3 relative to the BP adenine)\n",
      "* bp_scr - BP sequence score using a variable order Markov model\n",
      "* y_cont - Pyrimidine content between the BP adenine and the 3' splice site\n",
      "* ppt_off - Polypyrimidine tract offset relative to the BP adenine\n",
      "* ppt_len - Polypyrimidine tract length\n",
      "* ppt_scr - Polypyrimidine tract score\n",
      "* svm_scr - Final BP score using the SVM classifier\n",
      "\n",
      "### Single branchpoint per junction/intron\n",
      "\n",
      "SVM_BP can predict more than one branchpoint per \n",
      "intron (or none at all). I want to choose a \"best\"\n",
      "prediction for each intron for the branchpoint. This \n",
      "will make some downstream analyses easier. \n",
      "\n",
      "#### Annotated acceptors downstream of proximal cryptic junctions\n",
      "\n",
      "To simplify downstream analyses, I'm only going to keep \n",
      "predictions for pairs of proximal junctions and their \n",
      "downstream annotated junction when branchpoints are \n",
      "predicted for both. \n",
      "\n",
      "Note that while we can always figure out the annotated junction\n",
      "for a proximal cryptic junction, we may not always have coverage\n",
      "data for that annotated junction. This happens when the annotated\n",
      "junction's coverage is not above the cutoff we used when combining\n",
      "`SJ.out.tab` files. In practice this is rare and I think only observed\n",
      "for one cryptic junction/annotated junction pair here. We will exclude\n",
      "these junctions.\n",
      "\n",
      "Another a rare thing that can happen is that an annotated junction\n",
      "can have two cryptic junctions upstream. I think there are five annotated\n",
      "junctions here that have two cryptic junctions upstream. We will choose\n",
      "one of these cryptic acceptors and discard the other.\n",
      "\n",
      "#### Additional information\n",
      "\n",
      "I'd like to add some extra information to the dataframes\n",
      "that have the branchpoint results. \n",
      "\n",
      "* Annotated junction for proximal cryptic acceptors and vice versa.\n",
      "* Distance from cryptic acceptor to annotated acceptor for\n",
      "proximal cryptic junctions and their associated annotated \n",
      "junctions (`proximal_cryptic_dist`)\n",
      "* Whether associated proximal and annotated junctions share\n",
      "predicted branchpoints (`same_bp`)\n",
      "* Distance from branchpoint predicted for annotated junction to\n",
      "cryptic associated proximal cryptic junction (`bp_proximal_dist`)\n",
      "\n",
      "#### Examples\n",
      "\n",
      "I'm going to show a couple of examples of entries from `proximal_single_bp`\n",
      "and `annot_single_bp` to explain what some of the columns mean. For these \n",
      "examples, I'm going to show that last 50 bp of the intron preceding the \n",
      "**annotated acceptor**. Note that the branchpoint predictions for the cryptic\n",
      "proximal acceptors included the last 50 bp before the cryptic acceptor.\n",
      "I've also made the predicted branchpoint sequence \n",
      "and the cryptic acceptor lower case. \n",
      "\n",
      "This first example shows a case\n",
      "where the proximal cryptic acceptor and its downstream annotated \n",
      "acceptor share a predicted branchpoint. This example uses\n",
      " `chrX:49036156-49040186:-` and `chrX:49036186-49040186:-`.\n",
      "\n",
      "    proximal_single_bp distances\n",
      "          bp_proxmal_dist\n",
      "          |------------|\n",
      "                       |----proximal_cryptic_dist----|\n",
      "          |--ss_dist---|\n",
      "    CaactcacctCTCATTTCagTTGTTTTCTCCCACTCCTATGTCCTCCCAG\n",
      "          |-----------------ss_dist------------------|\n",
      "                       |----proximal_cryptic_dist----|\n",
      "          |------------|\n",
      "          bp_proxmal_dist\n",
      "                       \n",
      "    annot_single_bp distances\n",
      "                      \n",
      "This second example shows a case where the proximal cryptic acceptor\n",
      "and downstream annoated acceptor do not share predicted branchpoints. \n",
      "This example uses `chrX:9711733-9714083:-` and `chrX:9711733-9714083:-`.\n",
      "\n",
      "    proximal_single_bp distances  \n",
      "                  |bp_proxmal_dist-|\n",
      "                                   proximal_cryptic_dist\n",
      "                                   |------------------|\n",
      "          |---------ss_dist--------|\n",
      "    ccgtaaacaTgaataatgaACACCATACATAGTTCCTTCTGTTCTTCACAG\n",
      "                  |--------------ss_dist--------------|\n",
      "                                   |------------------|\n",
      "                                   proximal_cryptic_dist\n",
      "                  |bp_proxmal_dist-|"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_uniq_bp_results(all_bp):\n",
      "    df = all_bp.sort(['seq_id', 'bp_scr'], ascending=False).drop_duplicates('seq_id')\n",
      "    df.index = list(df.seq_id)\n",
      "    return df\n",
      "    \n",
      "f = ds.proximal_single_bp\n",
      "g = ds.annot_single_bp\n",
      "if (not os.path.exists(f)) or (not os.path.exists(g)):\n",
      "    proximal_single_bp = make_uniq_bp_results(proximal_all_bp)\n",
      "    annot_single_bp = make_uniq_bp_results(annot_all_bp)\n",
      "\n",
      "    # Add annotated jxn for proximal cryptic\n",
      "    proximal_single_bp['annotated'] = [ proximal_to_annot[x] for x in proximal_single_bp.index ]\n",
      "    # Keep one proximal junction per annotated junction\n",
      "    proximal_single_bp = proximal_single_bp.drop_duplicates(subset=['annotated'])\n",
      "    # Keep annotated/proximal junctions only if annotated\n",
      "    # junction has count data\n",
      "    s = set(proximal_single_bp.annotated) - set(counts.index)\n",
      "    proximal_single_bp = proximal_single_bp[proximal_single_bp.annotated.apply(lambda x: x not in s)]\n",
      "    # Keep proximal only if annotated had a branchpoint predicted\n",
      "    proximal_single_bp = proximal_single_bp[proximal_single_bp.annotated.apply(lambda x: x in annot_single_bp.index)]\n",
      "    # Update results for annotated junctions\n",
      "    annot_single_bp = annot_single_bp.ix[proximal_single_bp.annotated]\n",
      "    # Add proximal crytpic jxn for downstream annotated jxns\n",
      "    annot_to_proximal = pd.Series(dict(zip(proximal_single_bp.annotated, \n",
      "                                           proximal_single_bp.index)))\n",
      "    annot_single_bp['cryptic'] = annot_to_proximal.ix[annot_single_bp.index].values\n",
      "\n",
      "    # Add distance between annotated and proximal cryptic jxns\n",
      "    proximal_single_bp['proximal_cryptic_dist'] = results.ix[proximal_single_bp.index,\n",
      "                                                                'downstream_acceptor_dist']\n",
      "    annot_single_bp['proximal_cryptic_dist'] = results.ix[annot_single_bp.cryptic, \n",
      "                                                          'downstream_acceptor_dist'].values\n",
      "\n",
      "    # Add column indicating whether the branchpoints\n",
      "    # were predicted to be the same for the proximal \n",
      "    # cryptic junctions and their associated annotated \n",
      "    # junctions.\n",
      "    a = annot_single_bp.ss_dist\n",
      "    b = proximal_single_bp.proximal_cryptic_dist\n",
      "    c = proximal_single_bp.ss_dist\n",
      "    annot_single_bp['same_bp'] = False\n",
      "    annot_single_bp.ix[a == b + c, 'same_bp'] = True\n",
      "    proximal_single_bp['same_bp'] = False\n",
      "    proximal_single_bp.ix[b + c == a, 'same_bp'] = True\n",
      "\n",
      "    # Add distance from branchpoint predicted for annotated \n",
      "    # acceptor to cryptic acceptor\n",
      "    v = annot_single_bp.ss_dist - annot_single_bp.proximal_cryptic_dist\n",
      "    annot_single_bp['bp_proximal_dist'] = v\n",
      "    proximal_single_bp['bp_proximal_dist'] = v.ix[proximal_single_bp.annotated].values\n",
      "    \n",
      "    proximal_single_bp.to_csv(f, sep='\\t')\n",
      "    annot_single_bp.to_csv(g, sep='\\t')\n",
      "else:\n",
      "    proximal_single_bp = pd.read_table(f, index_col=0,\n",
      "                                       header=0)\n",
      "    annot_single_bp = pd.read_table(g, index_col=0,\n",
      "                                    header=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = ds.distal_single_bp\n",
      "if not os.path.exists(f):\n",
      "    distal_single_bp = make_uniq_bp_results(distal_all_bp)\n",
      "    distal_single_bp.to_csv(f, sep='\\t')\n",
      "else:\n",
      "    distal_single_bp = pd.read_table(f, index_col=0,\n",
      "                                     header=0)\n",
      "    \n",
      "f = ds.control_single_bp\n",
      "if not os.path.exists(f):\n",
      "    control_single_bp = make_uniq_bp_results(control_all_bp)\n",
      "    control_single_bp.to_csv(f, sep='\\t')\n",
      "else:\n",
      "    control_single_bp = pd.read_table(f, index_col=0,\n",
      "                                      header=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Second highest-scoring branchpoints\n",
      "\n",
      "Because `SVM_BP` can return multiple branchpoints\n",
      "for a given intron, I'd like to replace the branchpoint\n",
      "prediction for annotated junctions with upstream\n",
      "proximal cryptic junctions with the the second-highest\n",
      "scoring branchpoint *if* the distance between the \n",
      "highest scoring branchpoint and the cryptic junction is \n",
      "not between 13 and 17 base pairs. My hypothesis is that\n",
      "`SVM_BP` has a hard time identify the correct branchpoint \n",
      "for these annotated junctions because they are further\n",
      "from the 3' splice-site than is typical. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_second_highest_bp(seq_id, annot_all_bp=annot_all_bp):\n",
      "    df = annot_all_bp[annot_all_bp.seq_id == seq_id].sort('bp_scr', ascending=False)\n",
      "    df.index = arange(df.shape[0])\n",
      "    if df.shape[0] > 1:\n",
      "        return df.ix[1]\n",
      "    else:\n",
      "        return df.ix[0]\n",
      "    \n",
      "f = ds.proximal_single_bp_second\n",
      "g = ds.annot_single_bp_second\n",
      "if (not os.path.exists(f)) or (not os.path.exists(g)):\n",
      "    second_highest = dict()\n",
      "    for seq_id in annot_single_bp[(annot_single_bp.bp_proximal_dist < 13) |\n",
      "                                  (annot_single_bp.bp_proximal_dist > 17)].seq_id:\n",
      "        second_highest[seq_id] = get_second_highest_bp(seq_id)\n",
      "    annot_single_bp_second = pd.concat([annot_single_bp.drop(second_highest.keys()),\n",
      "                                        pd.DataFrame(second_highest).T])\n",
      "    annot_single_bp_second = annot_single_bp_second.ix[annot_single_bp.index,\n",
      "                                                       annot_single_bp.columns]\n",
      "    \n",
      "    proximal_single_bp_second = make_uniq_bp_results(proximal_all_bp)\n",
      "\n",
      "    # Add annotated jxn for proximal cryptic\n",
      "    proximal_single_bp_second['annotated'] = [ proximal_to_annot[x] for x in proximal_single_bp_second.index ]\n",
      "    # Keep one proximal junction per annotated junction\n",
      "    proximal_single_bp_second = proximal_single_bp_second.drop_duplicates(subset=['annotated'])\n",
      "    # Keep annotated/proximal junctions only if annotated\n",
      "    # junction has count data\n",
      "    s = set(proximal_single_bp_second.annotated) - set(counts.index)\n",
      "    proximal_single_bp_second = proximal_single_bp_second[proximal_single_bp_second.annotated.apply(lambda x: x not in s)]\n",
      "    # Keep proximal only if annotated had a branchpoint predicted\n",
      "    proximal_single_bp_second = proximal_single_bp_second[\n",
      "        proximal_single_bp_second.annotated.apply(lambda x: x in annot_single_bp_second.index)]\n",
      "    # Update results for annotated junctions\n",
      "    annot_single_bp_second = annot_single_bp_second.ix[proximal_single_bp_second.annotated]\n",
      "    # Add proximal crytpic jxn for downstream annotated jxns\n",
      "    annot_to_proximal_second = pd.Series(dict(zip(proximal_single_bp_second.annotated, \n",
      "                                           proximal_single_bp_second.index)))\n",
      "    annot_single_bp_second['cryptic'] = annot_to_proximal_second.ix[annot_single_bp_second.index].values\n",
      "\n",
      "    # Add distance between annotated and proximal cryptic jxns\n",
      "    proximal_single_bp_second['proximal_cryptic_dist'] = results.ix[proximal_single_bp_second.index,\n",
      "                                                                'downstream_acceptor_dist']\n",
      "    annot_single_bp_second['proximal_cryptic_dist'] = results.ix[annot_single_bp_second.cryptic, \n",
      "                                                          'downstream_acceptor_dist'].values\n",
      "\n",
      "    # Add column indicating whether the branchpoints\n",
      "    # were predicted to be the same for the proximal \n",
      "    # cryptic junctions and their associated annotated \n",
      "    # junctions.\n",
      "    a = annot_single_bp_second.ss_dist\n",
      "    b = proximal_single_bp_second.proximal_cryptic_dist\n",
      "    c = proximal_single_bp_second.ss_dist\n",
      "    annot_single_bp_second['same_bp'] = False\n",
      "    annot_single_bp_second.ix[a == b + c, 'same_bp'] = True\n",
      "    proximal_single_bp_second['same_bp'] = False\n",
      "    proximal_single_bp_second.ix[b + c == a, 'same_bp'] = True\n",
      "\n",
      "    # Add distance from branchpoint predicted for annotated \n",
      "    # acceptor to cryptic acceptor\n",
      "    v = annot_single_bp_second.ss_dist - annot_single_bp_second.proximal_cryptic_dist\n",
      "    annot_single_bp_second['bp_proximal_dist'] = v\n",
      "    proximal_single_bp_second['bp_proximal_dist'] = v.ix[proximal_single_bp_second.annotated].values\n",
      "    \n",
      "    proximal_single_bp_second.to_csv(f, sep='\\t')\n",
      "    annot_single_bp_second.to_csv(g, sep='\\t')\n",
      "else:\n",
      "    proximal_single_bp_second = pd.read_table(f, index_col=0,\n",
      "                                              header=0)\n",
      "    annot_single_bp_second = pd.read_table(g, index_col=0,\n",
      "                                           header=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### `AG` dinucleotides in control introns after branchpoint\n",
      "\n",
      "I want to identify where `AG` dinucleotides are located in the \n",
      "last 50 bp of the introns for the control junctions. Before I \n",
      "do this, I want to take a closer look at how SVM_BP defines distances.\n",
      "Take this sequence.\n",
      "\n",
      "    TCTTGAAAACAAATCCCATCTATTTAGTTCTTCAATTTGTTGTAG\n",
      "    \n",
      "This is the entire sequence from the beginning of the BP to the \n",
      "3' SS. The BP is made up of the first nine bases:\n",
      "\n",
      "    tcttgaaaa\n",
      "    \n",
      "SVM_BP calculates the distance from the BP to the 3' SS as 40. \n",
      "This sequence has length 40:\n",
      "\n",
      "    AAAACAAATCCCATCTATTTAGTTCTTCAATTTGTTGTAG\n",
      "    \n",
      "The first `A` in this sequence is the BP adenine. So the distance \n",
      "is defined from the BP adenine to the end of the AG at the 3' SS. \n",
      "Say we give my `find_ag` function (defined below) the following\n",
      "input:\n",
      "\n",
      "    AGTTTTTT\n",
      "    \n",
      "where the first `A` is the BP adenine. In this case, you may expect\n",
      "`find_ag` to return zero because the branchpoint adenine is the \n",
      "*beginning* of the `AG`. However, SVM_BP defines distance *including* \n",
      "the length of the `AG`, so I added two to the output of `find_ag()` \n",
      "to make it consistent with the lengths from SVM_BP. Now, given\n",
      "\n",
      "    AGTTTTTT\n",
      "    \n",
      "as input, the script will return two. Weird, I know."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_ag(seq, bp_seq):\n",
      "    \"\"\"Find AG dinucleotides after branchpoint\"\"\"\n",
      "    s = seq[seq.lower().find(bp_seq):-10]\n",
      "    L = s.upper().split('AG')[:-1]\n",
      "    if len(L) == 0:\n",
      "        return np.nan\n",
      "    else:\n",
      "        c = cumsum([ len(x) for x in L ])\n",
      "        return [ c[i] + 2 * (i + 1) for i in range(c.shape[0]) ]\n",
      "\n",
      "if not os.path.exists(ds.control_ag_dists):\n",
      "    f = open(ds.control_intron_seq, 'r')\n",
      "    lines = [ x.strip('>').strip() for x in f.readlines() ]\n",
      "    f.close()\n",
      "    control_intron_seq = dict(zip(lines[0::2],\n",
      "                                  lines[1::2]))\n",
      "\n",
      "    ag_dinuc = dict()\n",
      "    for jxn in control_single_bp.index:\n",
      "        ag_dinuc[jxn] = find_ag(control_intron_seq[jxn],\n",
      "                                control_single_bp.ix[jxn, 'bp_seq'])\n",
      "    f = open(ds.control_ag_dists, 'w')\n",
      "    for k in ag_dinuc:\n",
      "        s = k\n",
      "        if type(ag_dinuc[k]) == list:\n",
      "            s += '\\t'.join([ str(x) for x in ag_dinuc[k] ])\n",
      "        s += '\\n'\n",
      "        f.write(s)\n",
      "    f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    }
   ],
   "metadata": {}
  }
 ]
}