{
 "metadata": {
  "name": "",
  "signature": "sha256:be84ebbdc2e3d8da8bbaa966be632aebeb614387d3a6eeab0e8feed7eea03dcf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Branchpoint Analysis\n",
      "\n",
      "In this notebook, I'm going to use SVM_BP to predict branchpoints. \n",
      "I'll predict branchpoints for junctions with cryptic acceptors whose usage differs \n",
      "significantly between the *SF3B1* mutant and wild-type samples. I'll split\n",
      "these into junction with cryptic acceptors 10-30 bp upstream of an annotated \n",
      "acceptor and junctions not 10-30 bp upstream of an annotated acceptor. For the\n",
      "cryptic junctions with an acceptor 10-30 bp upstream of an annotated acceptor,\n",
      "I'll also predict the branchpoint for the annotated acceptor. I will also \n",
      "choose some \"control\" junctions that are highly expressed but don't have\n",
      "proximal cryptic junctions and predict branchpoints for those."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob\n",
      "import os\n",
      "import shutil\n",
      "import subprocess\n",
      "from urllib2 import urlopen\n",
      "\n",
      "from Bio.Seq import Seq\n",
      "import ds2014 as ds\n",
      "import pandas as pd\n",
      "import pybedtools as pbt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "curdir = os.getcwd()\n",
      "outdir = os.path.join(os.path.split(curdir)[0], \n",
      "                      'output', \n",
      "                      'branchpoint_analysis')\n",
      "ds.makedir(outdir)\n",
      "\n",
      "results = pd.read_table(ds.brca_cll_um_dexseq_results,\n",
      "                        index_col=0,\n",
      "                        header=0)\n",
      "\n",
      "counts = pd.read_table(ds.brca_cll_um_sj_counts,\n",
      "                       index_col=0,\n",
      "                       header=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Define junctions\n",
      "\n",
      "Let's define the different classes of junctions we are looking at:\n",
      "* proximal cryptic junction with novel acceptor 10-30 bp upstream \n",
      "of annotated acceptor\n",
      "* distal cryptic junction with novel acceptor **not** 10-30 bp \n",
      "upstream of annotated acceptor\n",
      "* annotated junction with proximal cryptic acceptor 10-30 bp upstream\n",
      "* control junction\n",
      "\n",
      "### Proximal cryptic junctions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = ds.proximal_jxns\n",
      "if not os.path.exists(f):\n",
      "    proximal_jxns = results[(results.padjust < ds.dexseq_p_cutoff) &\n",
      "                            (results.downstream_acceptor_dist <= 30) &\n",
      "                            (results.downstream_acceptor_dist >= 10) &\n",
      "                            (results['log2fold(MUT/WT)'] > 0)]\n",
      "    proximal_jxns = pd.Series(proximal_jxns.index)\n",
      "    proximal_jxns.to_csv(f, sep='\\t', index=False, header=False)\n",
      "else:\n",
      "    proximal_jxns = pd.read_table(f, header=None, squeeze=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Distal cryptic junctions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = ds.distal_jxns\n",
      "if not os.path.exists(f):\n",
      "    distal_jxns = results[(results.padjust < ds.dexseq_p_cutoff) &\n",
      "                          (results.downstream_acceptor_dist > 30) &\n",
      "                          (results['log2fold(MUT/WT)'] > 0)]\n",
      "    distal_jxns = pd.Series(distal_jxns.index)\n",
      "    distal_jxns.to_csv(f, sep='\\t', index=False, header=False)\n",
      "else:\n",
      "    distal_jxns = pd.read_table(f, header=None, squeeze=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Annotated junctions downstream of proximal cryptic junctions\n",
      "\n",
      "Note that while we can always figure out the annotated junction\n",
      "for a proximal cryptic junction, we may not always have coverage\n",
      "data for that annotated junction. This happens when the annotated\n",
      "junction's coverage is not above the cutoff we used when combining\n",
      "`SJ.out.tab` files. In practice this is rare and I think only observed\n",
      "for one cryptic junction/annotated junction pair here.\n",
      "\n",
      "Another a rare thing that can happen is that an annotated junction\n",
      "can have two cryptic junctions upstream. I think there are five annotated\n",
      "junctions here that have two cryptic junctions upstream."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_annotated_jxn(row):\n",
      "    \"\"\"\n",
      "    Define the downstream annotated junction for a \n",
      "    junction with a novel acceptor using a row\n",
      "    from the results table\n",
      "    \"\"\"\n",
      "    if row['strand'] == '+':        \n",
      "        return '{}:{}-{}:{}'.format(row['chrom'], \n",
      "                                    row['start'],\n",
      "                                    row['end'] + int(row['downstream_acceptor_dist']),\n",
      "                                    row['strand'])\n",
      "    if row['strand'] == '-':\n",
      "        return '{}:{}-{}:{}'.format(row['chrom'], \n",
      "                                    row['start'] - int(row['downstream_acceptor_dist']),\n",
      "                                    row['end'],\n",
      "                                    row['strand'])\n",
      "\n",
      "f = ds.annot_jxns\n",
      "if not os.path.exists(f):\n",
      "    annot_jxns = pd.Series(results.ix[proximal_jxns].apply(lambda x: get_annotated_jxn(x), axis=1))\n",
      "    annot_jxns.index = arange(annot_jxns.shape[0])\n",
      "    annot_jxns.to_csv(f, sep='\\t', index=False, header=False)\n",
      "else:\n",
      "    annot_jxns = pd.read_table(f, header=None, squeeze=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I'll also make a mapping between the proximal cryptic \n",
      "junctions and the annotated junctions 10-30 bp downsteam."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = ds.proximal_to_annot\n",
      "if not os.path.exists(f):\n",
      "    proximal_to_annot = pd.Series(annot_jxns.values,\n",
      "                                  index=proximal_jxns,\n",
      "                                  name='annotated')\n",
      "    proximal_to_annot.index.name = 'proximal_cryptic'\n",
      "    proximal_to_annot.to_csv(f, sep='\\t')\n",
      "else:\n",
      "    proximal_to_annot = pd.read_table(f, index_col=0, header=0,\n",
      "                                      squeeze=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Control junctions\n",
      "\n",
      "For control junctions, we will choose junctions that\n",
      "are annotated in Gencode, whose average coverage over \n",
      "all samples is greater than 100, and whose donor does \n",
      "not have any novel acceptors."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = ds.control_jxns\n",
      "if not os.path.exists(f):\n",
      "    donors = set(results[results.ext_annotated == False]['donor'])\n",
      "    control_jxns = results[(results.ext_annotated) &\n",
      "                           (results.donor.apply(lambda x: x not in donors)) & \n",
      "                           (counts.ix[results.index].mean(axis=1) > 100)]\n",
      "    control_jxns = pd.Series(control_jxns.index)\n",
      "    control_jxns.to_csv(f, sep='\\t', index=False, header=False)\n",
      "else:\n",
      "    control_jxns = pd.read_table(f, header=None, squeeze=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Sequence files\n",
      "\n",
      "To predict branchpoints, we need the last 50 bp of the intron for\n",
      "each junction. I'll download hg19 from UCSC, convert to fasta and\n",
      "index with samtools. Note that I'm assuming samtools is in your path."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = ds.hg19\n",
      "if not os.path.exists(f):\n",
      "    req = urlopen('http://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/hg19.2bit')\n",
      "    dest = os.path.join(ds.root, 'ext_data', 'hg19.2bit')\n",
      "    with open(dest, 'w') as d:\n",
      "        shutil.copyfileobj(req, d)\n",
      "    req = urlopen('http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/twoBitToFa')\n",
      "    dest = os.path.join(ds.root, 'ext_data', 'twoBitToFa')\n",
      "    with open(dest, 'w') as d:\n",
      "        shutil.copyfileobj(req, d)\n",
      "    !chmod 755 ../ext_data/twoBitToFa\n",
      "    !../ext_data/twoBitToFa ../ext_data/hg19.2bit ../ext_data/hg19.fa\n",
      "    !samtools faidx ../ext_data/hg19.fa"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now I'll get the last 50 bp of each intron. I'll reverse complement\n",
      "minus strand sequence."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_seq(row):\n",
      "    \"\"\"Get last 50 bp of intron for a row from results table\"\"\"\n",
      "    if row['strand'] == '+':\n",
      "        seq_pos = '{0}:{1}-{2}'.format(row['chrom'],\n",
      "                                       int(row['end'] - 49),\n",
      "                                       int(row['end']))\n",
      "        seq = pbt.BedTool.seq(seq_pos, ds.hg19)\n",
      "    elif row['strand'] == '-':\n",
      "        seq_pos = '{0}:{1}-{2}'.format(row['chrom'],\n",
      "                                       int(row['start']),\n",
      "                                       int(row['start'] + 49))\n",
      "        seq = pbt.BedTool.seq(seq_pos, ds.hg19)\n",
      "        my_seq = Seq(seq)\n",
      "        seq = my_seq.reverse_complement().tostring()\n",
      "    return seq\n",
      "\n",
      "def make_intron_fasta(res, f):\n",
      "    \"\"\"Make fasta file of last 50 bp of intron for results table\"\"\"\n",
      "    r = res.apply(lambda x: get_seq(x), axis=1)\n",
      "    with open(f, 'w') as fout:\n",
      "        for i in r.index:\n",
      "            fout.write('>{}\\n'.format(i))\n",
      "            fout.write(r[i] + '\\n')\n",
      "\n",
      "f = ds.proximal_intron_seq\n",
      "if not os.path.exists(f):\n",
      "    make_intron_fasta(results.ix[proximal_jxns], f)\n",
      "\n",
      "f = ds.distal_intron_seq\n",
      "if not os.path.exists(f):\n",
      "    make_intron_fasta(results.ix[distal_jxns], f)\n",
      "    \n",
      "f = ds.annot_intron_seq\n",
      "if not os.path.exists(f):\n",
      "    # We have to account for the possibility that the \n",
      "    # annotated junction didn't make it through the sjout filtering.\n",
      "    make_intron_fasta(results.ix[annot_jxns].dropna(subset=['chrom']).drop_duplicates(), f)\n",
      "    \n",
      "f = ds.control_intron_seq\n",
      "if not os.path.exists(f):\n",
      "    make_intron_fasta(results.ix[control_jxns], f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Predict branchpoints\n",
      "\n",
      "I'm going to use SVM_BP to predict branchpoint locations.\n",
      "I have forked [my own version](https://github.com/cdeboever3/svm-bpfinder) of SVM_BP where I have changed\n",
      "a hard-coded parameter that specifies the minimum distance \n",
      "from the 3' splice-site to the branchpoint. This was originally\n",
      "15 bp but I changed to 8 bp because if proximal cryptic junctions\n",
      "use the same branchpoint as their downstream annotated acceptors,\n",
      "they may be closer than 15 bp to the branchpoint."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict_branchpoints(intron_fasta):\n",
      "    lines = subprocess.check_output([os.path.join(ds.root, 'software', 'svm-bpfinder', 'svm_bpfinder.py'),\n",
      "                                     intron_fasta, 'Hsap', '50'])\n",
      "    lines = [ x.split('\\t') for x in lines.split('\\n') ]\n",
      "    return pd.DataFrame(lines[1:], columns=lines[0])\n",
      "\n",
      "f = ds.proximal_all_bp\n",
      "if not os.path.exists(f):\n",
      "    proximal_all_bp = predict_branchpoints(ds.proximal_intron_seq)\n",
      "else:\n",
      "    proximal_all_bp = pd.read_table(f, index_col=0, header=0)\n",
      "    \n",
      "f = ds.distal_all_bp\n",
      "if not os.path.exists(f):\n",
      "    distal_all_bp = predict_branchpoints(ds.distal_intron_seq)\n",
      "else:\n",
      "    distal_all_bp = pd.read_table(f, index_col=0, header=0)\n",
      "    \n",
      "f = ds.annot_all_bp\n",
      "if not os.path.exists(f):\n",
      "    annot_all_bp = predict_branchpoints(ds.annot_intron_seq)\n",
      "else:\n",
      "    annot_all_bp = pd.read_table(f, index_col=0, header=0)\n",
      "    \n",
      "f = ds.control_all_bp\n",
      "if not os.path.exists(f):\n",
      "    control_all_bp = predict_branchpoints(ds.control_intron_seq)\n",
      "else:\n",
      "    control_all_bp = pd.read_table(f, index_col=0, header=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Parse branchpoints\n",
      "\n",
      "##### Additional information\n",
      "\n",
      "I'd like to add some extra information to the dataframes\n",
      "that have the branchpoint results.\n",
      "\n",
      "* Rank of score for that intron\n",
      "\n",
      "##### Single branchpoint per junction/intron\n",
      "SVM_BP can predict more than one branchpoint per \n",
      "intron (or none at all). I want to choose a \"best\"\n",
      "prediction for each intron for the branchpoint. This \n",
      "will make some downstream analyses easier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}